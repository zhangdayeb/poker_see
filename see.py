#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰‘å…‹è¯†åˆ«æµ‹è¯•ç³»ç»Ÿ - see.py (ç»Ÿä¸€è¯†åˆ«å™¨ç‰ˆæœ¬)
ä¸šåŠ¡é€»è¾‘:
1. è¯»å–æ‘„åƒå¤´é…ç½®
2. è½®è¯¢æ‹ç…§å’Œè¯†åˆ« (ä½¿ç”¨ç»Ÿä¸€è¯†åˆ«å™¨)
3. ä¿å­˜è¯†åˆ«ç»“æœ
4. æ˜¾ç¤ºå®æ—¶ç»Ÿè®¡
"""

import sys
import time
import json
import signal
import argparse
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional

# è·¯å¾„è®¾ç½®
def setup_project_paths():
    """è®¾ç½®é¡¹ç›®è·¯å¾„"""
    current_file = Path(__file__).resolve()
    project_root = current_file.parent
    
    project_root_str = str(project_root)
    if project_root_str not in sys.path:
        sys.path.insert(0, project_root_str)
    
    return project_root

PROJECT_ROOT = setup_project_paths()

class UnifiedSeeSystem:
    """åŸºäºç»Ÿä¸€è¯†åˆ«å™¨çš„æµ‹è¯•ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.shutdown_requested = False
        
        # ç³»ç»Ÿé…ç½®
        self.config = {
            'recognition_interval': 3,  # è¯†åˆ«é—´éš”(ç§’)
            'camera_switch_delay': 1,   # æ‘„åƒå¤´åˆ‡æ¢å»¶è¿Ÿ(ç§’)
            'max_retry_times': 2,       # æœ€å¤§é‡è¯•æ¬¡æ•°
            'save_results': True,       # ä¿å­˜è¯†åˆ«ç»“æœ
            'show_detailed_results': True,  # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
            'show_quality_info': True,  # æ˜¾ç¤ºè´¨é‡ä¿¡æ¯
        }
        
        # ç»Ÿä¸€è¯†åˆ«å™¨é…ç½®
        self.recognition_config = {
            # è¾“å‡ºæ ¼å¼
            'output_format': 'standard',  # standard, simple, database
            
            # è¯†åˆ«æ–¹æ³•é…ç½®
            'yolo_enabled': True,
            'yolo_confidence_threshold': 0.3,
            'yolo_high_confidence_threshold': 0.8,
            
            'ocr_enabled': True,
            'ocr_confidence_threshold': 0.3,
            'ocr_prefer_paddle': True,
            
            'opencv_suit_enabled': True,
            'opencv_suit_confidence_threshold': 0.4,
            
            # èåˆç­–ç•¥
            'fusion_strategy': 'weighted',  # weighted, voting, priority
            'min_confidence_for_result': 0.3,
            'enable_result_validation': True,
            
            # ç»“æœæ•´åˆ
            'enable_result_merging': True,
            'quality_assessment_enabled': True,
            'duplicate_detection_enabled': True,
            'include_quality_metrics': True,
            'include_debug_info': False,
        }
        
        # æ‘„åƒå¤´é…ç½®
        self.enabled_cameras = []
        self.current_camera_index = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'start_time': datetime.now(),
            'total_cycles': 0,
            'camera_stats': {},
            'last_results': {},
            'recognition_method_stats': {
                'yolo_complete': 0,
                'hybrid_combined': 0,
                'single_method': 0,
                'failed': 0
            },
            'quality_stats': {
                'excellent': 0,
                'good': 0,
                'average': 0,
                'poor': 0,
                'very_poor': 0
            },
            'performance_stats': {
                'total_recognition_time': 0.0,
                'average_recognition_time': 0.0,
                'fastest_recognition': float('inf'),
                'slowest_recognition': 0.0
            }
        }
        
        # ç»“æœä¿å­˜ç›®å½•
        self.result_dir = PROJECT_ROOT / "result" / "see_results"
        self.result_dir.mkdir(parents=True, exist_ok=True)
        
        # æ˜¾ç¤ºæ§åˆ¶
        self.display_lock = threading.Lock()
        
        print("ğŸš€ ç»Ÿä¸€è¯†åˆ«å™¨ç‰ˆæµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def step1_load_camera_config(self) -> bool:
        """æ­¥éª¤1: è¯»å–æ‘„åƒå¤´é…ç½®"""
        try:
            print("\nğŸ“· æ­¥éª¤1: è¯»å–æ‘„åƒå¤´é…ç½®")
            print("-" * 50)
            
            # ä½¿ç”¨é…ç½®ç®¡ç†å™¨
            from src.core.config_manager import get_all_cameras
            
            result = get_all_cameras()
            if result['status'] != 'success':
                print(f"âŒ è·å–æ‘„åƒå¤´é…ç½®å¤±è´¥: {result['message']}")
                return False
            
            cameras = result['data']['cameras']
            if not cameras:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ‘„åƒå¤´é…ç½®")
                return False
            
            # è¿‡æ»¤å¯ç”¨çš„æ‘„åƒå¤´
            self.enabled_cameras = [c for c in cameras if c.get('enabled', True)]
            if not self.enabled_cameras:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ‘„åƒå¤´")
                return False
            
            print(f"âœ… æ‰¾åˆ° {len(self.enabled_cameras)} ä¸ªå¯ç”¨çš„æ‘„åƒå¤´:")
            for i, camera in enumerate(self.enabled_cameras):
                camera_id = camera['id']
                
                # åˆå§‹åŒ–æ‘„åƒå¤´ç»Ÿè®¡
                self.stats['camera_stats'][camera_id] = {
                    'total_attempts': 0,
                    'successful_recognitions': 0,
                    'failed_recognitions': 0,
                    'last_recognition_time': None,
                    'last_result': None,
                    'average_duration': 0.0,
                    'total_duration': 0.0,
                    'best_quality_score': 0.0,
                    'recognition_method_counts': {
                        'yolo_complete': 0,
                        'hybrid_combined': 0,
                        'single_method': 0
                    },
                    'quality_history': []
                }
                
                print(f"   {i+1}. {camera['name']} (ID: {camera_id}) - IP: {camera['ip']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è¯»å–æ‘„åƒå¤´é…ç½®å¤±è´¥: {e}")
            return False
    
    def step2_recognize_camera_unified(self, camera_id: str) -> Dict[str, Any]:
        """æ­¥éª¤2: ä½¿ç”¨ç»Ÿä¸€è¯†åˆ«å™¨è¯†åˆ«æ‘„åƒå¤´"""
        try:
            print(f"   ğŸ§  ä½¿ç”¨ç»Ÿä¸€è¯†åˆ«å™¨è¯†åˆ«...")
            
            # å¯¼å…¥ç»Ÿä¸€è¯†åˆ«å™¨
            from src.processors.poker_hybrid_recognizer import recognize_camera_complete
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # ä½¿ç”¨ç»Ÿä¸€è¯†åˆ«å™¨ - ä¸€è¡Œä»£ç å®Œæˆæ‰€æœ‰å·¥ä½œ
            result = recognize_camera_complete(
                camera_id=camera_id,
                image_path=None,  # è‡ªåŠ¨æ‹ç…§
                config=self.recognition_config
            )
            
            # è®¡ç®—è€—æ—¶
            duration = time.time() - start_time
            result['actual_duration'] = duration
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_camera_stats(camera_id, result, duration)
            
            return result
            
        except Exception as e:
            return {
                'success': False,
                'camera_id': camera_id,
                'error': str(e),
                'error_code': 'UNIFIED_RECOGNITION_ERROR',
                'actual_duration': 0.0
            }
    
    def step3_save_recognition_result(self, camera_id: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """æ­¥éª¤3: ä¿å­˜è¯†åˆ«ç»“æœ"""
        try:
            if not self.config['save_results']:
                return {'success': True, 'message': 'ç»“æœä¿å­˜å·²ç¦ç”¨'}
            
            print(f"   ğŸ’¾ ä¿å­˜è¯†åˆ«ç»“æœ...")
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"recognition_{camera_id}_{timestamp}.json"
            file_path = self.result_dir / filename
            
            # ä¿å­˜ç»“æœ
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜æœ€æ–°ç»“æœ
            self.stats['last_results'][camera_id] = result
            
            print(f"   âœ… ç»“æœå·²ä¿å­˜: {filename}")
            
            return {
                'success': True,
                'file_path': str(file_path),
                'filename': filename
            }
            
        except Exception as e:
            print(f"   âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _update_camera_stats(self, camera_id: str, result: Dict[str, Any], duration: float):
        """æ›´æ–°æ‘„åƒå¤´ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = self.stats['camera_stats'][camera_id]
            
            # åŸºæœ¬ç»Ÿè®¡
            stats['total_attempts'] += 1
            stats['total_duration'] += duration
            stats['average_duration'] = stats['total_duration'] / stats['total_attempts']
            
            if result['success']:
                stats['successful_recognitions'] += 1
                stats['last_recognition_time'] = datetime.now().strftime('%H:%M:%S')
                stats['last_result'] = result
                
                # æ›´æ–°è¯†åˆ«æ–¹æ³•ç»Ÿè®¡
                self._update_recognition_method_stats(camera_id, result)
                
                # æ›´æ–°è´¨é‡ç»Ÿè®¡
                if 'quality' in result:
                    self._update_quality_stats(camera_id, result['quality'])
                
                # æ›´æ–°å…¨å±€è¯†åˆ«æ–¹æ³•ç»Ÿè®¡
                self._update_global_method_stats(result)
                
            else:
                stats['failed_recognitions'] += 1
                self.stats['recognition_method_stats']['failed'] += 1
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            perf_stats = self.stats['performance_stats']
            perf_stats['total_recognition_time'] += duration
            perf_stats['fastest_recognition'] = min(perf_stats['fastest_recognition'], duration)
            perf_stats['slowest_recognition'] = max(perf_stats['slowest_recognition'], duration)
            
            total_recognitions = sum(self.stats['recognition_method_stats'].values())
            if total_recognitions > 0:
                perf_stats['average_recognition_time'] = perf_stats['total_recognition_time'] / total_recognitions
                
        except Exception as e:
            print(f"âš ï¸  æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    def _update_recognition_method_stats(self, camera_id: str, result: Dict[str, Any]):
        """æ›´æ–°è¯†åˆ«æ–¹æ³•ç»Ÿè®¡"""
        try:
            camera_stats = self.stats['camera_stats'][camera_id]
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç»“æœåˆå¹¶
            if result.get('merge_enabled', False):
                # æ£€æŸ¥è´¨é‡ä¿¡æ¯åˆ¤æ–­æ–¹æ³•ç±»å‹
                summary = result.get('summary', {})
                successful_positions = summary.get('successful_positions', 0)
                
                if successful_positions >= 4:  # å¤§éƒ¨åˆ†ä½ç½®è¯†åˆ«æˆåŠŸï¼Œå¯èƒ½æ˜¯YOLOä¸»å¯¼
                    camera_stats['recognition_method_counts']['yolo_complete'] += 1
                else:  # éƒ¨åˆ†æˆåŠŸï¼Œå¯èƒ½æ˜¯æ··åˆæ–¹æ³•
                    camera_stats['recognition_method_counts']['hybrid_combined'] += 1
            else:
                # ç®€å•æ¨¡å¼
                camera_stats['recognition_method_counts']['single_method'] += 1
                
        except Exception:
            pass  # å¿½ç•¥ç»Ÿè®¡é”™è¯¯
    
    def _update_quality_stats(self, camera_id: str, quality_info: Dict[str, Any]):
        """æ›´æ–°è´¨é‡ç»Ÿè®¡"""
        try:
            camera_stats = self.stats['camera_stats'][camera_id]
            quality_score = quality_info.get('quality_score', 0.0)
            quality_level = quality_info.get('quality_level', '').lower()
            
            # æ›´æ–°æ‘„åƒå¤´æœ€ä½³è´¨é‡
            camera_stats['best_quality_score'] = max(camera_stats['best_quality_score'], quality_score)
            
            # æ›´æ–°è´¨é‡å†å²
            camera_stats['quality_history'].append(quality_score)
            if len(camera_stats['quality_history']) > 10:
                camera_stats['quality_history'] = camera_stats['quality_history'][-10:]
            
            # æ›´æ–°å…¨å±€è´¨é‡ç»Ÿè®¡
            quality_mapping = {
                'ä¼˜ç§€': 'excellent',
                'è‰¯å¥½': 'good',
                'ä¸€èˆ¬': 'average',
                'è¾ƒå·®': 'poor',
                'å¾ˆå·®': 'very_poor'
            }
            
            for chinese, english in quality_mapping.items():
                if chinese in quality_level:
                    self.stats['quality_stats'][english] += 1
                    break
                    
        except Exception:
            pass  # å¿½ç•¥ç»Ÿè®¡é”™è¯¯
    
    def _update_global_method_stats(self, result: Dict[str, Any]):
        """æ›´æ–°å…¨å±€æ–¹æ³•ç»Ÿè®¡"""
        try:
            if result.get('merge_enabled', False):
                summary = result.get('summary', {})
                successful_positions = summary.get('successful_positions', 0)
                
                if successful_positions >= 4:
                    self.stats['recognition_method_stats']['yolo_complete'] += 1
                else:
                    self.stats['recognition_method_stats']['hybrid_combined'] += 1
            else:
                self.stats['recognition_method_stats']['single_method'] += 1
                
        except Exception:
            pass  # å¿½ç•¥ç»Ÿè®¡é”™è¯¯
    
    def run_main_loop(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        try:
            print(f"\nğŸ”„ å¼€å§‹ç»Ÿä¸€è¯†åˆ«å™¨æµ‹è¯•å¾ªç¯")
            print(f"   è¯†åˆ«é—´éš”: {self.config['recognition_interval']} ç§’")
            print(f"   åˆ‡æ¢å»¶è¿Ÿ: {self.config['camera_switch_delay']} ç§’")
            print(f"   å¯ç”¨æ‘„åƒå¤´: {len(self.enabled_cameras)} ä¸ª")
            print(f"   èåˆç­–ç•¥: {self.recognition_config['fusion_strategy']}")
            print(f"   ç»“æœåˆå¹¶: {'å¯ç”¨' if self.recognition_config['enable_result_merging'] else 'ç¦ç”¨'}")
            print(f"   ä¿å­˜ç»“æœ: {'å¯ç”¨' if self.config['save_results'] else 'ç¦ç”¨'}")
            print("=" * 60)
            
            while not self.shutdown_requested:
                cycle_start_time = time.time()
                self.stats['total_cycles'] += 1
                
                # æ˜¾ç¤ºå¾ªç¯ä¿¡æ¯
                self._display_cycle_header()
                
                # è½®è¯¢å¤„ç†æ¯ä¸ªæ‘„åƒå¤´
                for i, camera in enumerate(self.enabled_cameras):
                    if self.shutdown_requested:
                        break
                    
                    camera_id = camera['id']
                    camera_name = camera.get('name', f'æ‘„åƒå¤´{camera_id}')
                    
                    # æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ‘„åƒå¤´
                    self._display_camera_processing(i + 1, len(self.enabled_cameras), camera_name, camera_id)
                    
                    # æ‰§è¡Œå®Œæ•´æµç¨‹
                    success = self._process_single_camera_workflow(camera_id)
                    
                    # æ‘„åƒå¤´åˆ‡æ¢å»¶è¿Ÿ
                    if i < len(self.enabled_cameras) - 1 and not self.shutdown_requested:
                        time.sleep(self.config['camera_switch_delay'])
                
                # æ˜¾ç¤ºæœ¬è½®ç»Ÿè®¡
                cycle_duration = time.time() - cycle_start_time
                self._display_cycle_summary(cycle_duration)
                
                # å¾ªç¯é—´éš”
                remaining_time = max(0, self.config['recognition_interval'] - cycle_duration)
                if remaining_time > 0 and not self.shutdown_requested:
                    self._display_waiting(remaining_time)
                    time.sleep(remaining_time)
                    
        except KeyboardInterrupt:
            print("\nâ¹ï¸  æ¥æ”¶åˆ°åœæ­¢ä¿¡å·")
            self.shutdown_requested = True
        except Exception as e:
            print(f"\nâŒ ä¸»å¾ªç¯å¼‚å¸¸: {e}")
            self.shutdown_requested = True
    
    def _process_single_camera_workflow(self, camera_id: str) -> bool:
        """å¤„ç†å•ä¸ªæ‘„åƒå¤´çš„å®Œæ•´å·¥ä½œæµç¨‹"""
        workflow_start_time = time.time()
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€è¯†åˆ«å™¨è¿›è¡Œè¯†åˆ«
            recognition_result = self.step2_recognize_camera_unified(camera_id)
            
            if not recognition_result['success']:
                self._display_step_result("ç»Ÿä¸€è¯†åˆ«", False, 
                                        recognition_result.get('error', 'è¯†åˆ«å¤±è´¥'), 
                                        recognition_result.get('actual_duration', 0))
                return False
            
            # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
            self._display_recognition_results(camera_id, recognition_result)
            
            # ä¿å­˜ç»“æœ
            save_result = self.step3_save_recognition_result(camera_id, recognition_result)
            self._display_step_result("ä¿å­˜ç»“æœ", save_result['success'], 
                                    save_result.get('filename', save_result.get('message', '')), 0)
            
            # æ˜¾ç¤ºæ€»è€—æ—¶
            total_duration = time.time() - workflow_start_time
            print(f"      ğŸ’« æ€»è€—æ—¶: {total_duration:.2f}ç§’")
            
            return True
            
        except Exception as e:
            print(f"      âŒ å·¥ä½œæµç¨‹å¼‚å¸¸: {e}")
            return False
    
    def _display_cycle_header(self):
        """æ˜¾ç¤ºå¾ªç¯å¤´éƒ¨ä¿¡æ¯"""
        with self.display_lock:
            current_time = datetime.now().strftime('%H:%M:%S')
            print(f"\nğŸ”„ ç¬¬ {self.stats['total_cycles']} è½®å¾ªç¯ ({current_time})")
            print("=" * 60)
    
    def _display_camera_processing(self, current: int, total: int, camera_name: str, camera_id: str):
        """æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ‘„åƒå¤´"""
        with self.display_lock:
            print(f"\nğŸ“· ({current}/{total}) {camera_name} (ID: {camera_id})")
            print("-" * 40)
    
    def _display_step_result(self, step_name: str, success: bool, message: str, duration: float):
        """æ˜¾ç¤ºæ­¥éª¤ç»“æœ"""
        with self.display_lock:
            status_icon = "âœ…" if success else "âŒ"
            if duration > 0:
                print(f"      {status_icon} {step_name}: {message} ({duration:.2f}s)")
            else:
                print(f"      {status_icon} {step_name}: {message}")
    
    def _display_recognition_results(self, camera_id: str, result: Dict[str, Any]):
        """æ˜¾ç¤ºè¯†åˆ«ç»“æœ"""
        with self.display_lock:
            summary = result.get('summary', {})
            success_count = summary.get('successful_positions', 0)
            total_count = summary.get('total_positions', 6)
            success_rate = summary.get('success_rate', 0)
            duration = result.get('total_duration', 0)
            
            print(f"      âœ… ç»Ÿä¸€è¯†åˆ«: {success_count}/{total_count} æˆåŠŸ ({success_rate:.1f}%) ({duration:.2f}s)")
            
            # æ˜¾ç¤ºè¯†åˆ«åˆ°çš„å¡ç‰Œ
            recognized_cards = summary.get('recognized_cards', [])
            if recognized_cards:
                cards_str = " | ".join(recognized_cards)
                print(f"         ğŸ´ è¯†åˆ«ç»“æœ: {cards_str}")
            
            # æ˜¾ç¤ºè´¨é‡ä¿¡æ¯
            if self.config['show_quality_info'] and 'quality' in result:
                quality = result['quality']
                quality_level = quality.get('quality_level', 'N/A')
                quality_score = quality.get('quality_score', 0)
                print(f"         ğŸ† è´¨é‡: {quality_level} ({quality_score:.3f})")
            
            # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
            if self.config['show_detailed_results']:
                self._display_detailed_positions(result.get('positions', {}))
            
            # æ˜¾ç¤ºè­¦å‘Š
            warnings = result.get('warnings', [])
            if warnings:
                print(f"         âš ï¸  è­¦å‘Š: {'; '.join(warnings)}")
    
    def _display_detailed_positions(self, positions: Dict[str, Any]):
        """æ˜¾ç¤ºè¯¦ç»†ä½ç½®ç»“æœ"""
        with self.display_lock:
            position_names = {
                'zhuang_1': 'åº„1', 'zhuang_2': 'åº„2', 'zhuang_3': 'åº„3',
                'xian_1': 'é—²1', 'xian_2': 'é—²2', 'xian_3': 'é—²3'
            }
            
            details = []
            for position in ['zhuang_1', 'zhuang_2', 'zhuang_3', 'xian_1', 'xian_2', 'xian_3']:
                pos_result = positions.get(position, {})
                pos_name = position_names.get(position, position)
                
                if pos_result.get('success', False):
                    display_name = pos_result.get('display_name', 'N/A')
                    confidence = pos_result.get('confidence', 0)
                    method = pos_result.get('method', 'unknown')
                    
                    # ç®€åŒ–æ–¹æ³•æ˜¾ç¤º
                    method_short = 'Y' if method == 'yolo' else ('H' if 'hybrid' in method else 'O')
                    
                    details.append(f"{pos_name}:{display_name}({confidence:.2f})[{method_short}]")
                else:
                    details.append(f"{pos_name}:-- ")
            
            if details:
                details_str = " | ".join(details)
                print(f"         ğŸ“‹ è¯¦ç»†: {details_str}")
    
    def _display_cycle_summary(self, cycle_duration: float):
        """æ˜¾ç¤ºå¾ªç¯æ±‡æ€»"""
        with self.display_lock:
            print(f"\nğŸ“Š æœ¬è½®æ±‡æ€»: è€—æ—¶ {cycle_duration:.2f}ç§’")
            
            # æ˜¾ç¤ºå…¨å±€è¯†åˆ«æ–¹æ³•ç»Ÿè®¡
            method_stats = self.stats['recognition_method_stats']
            total_recognitions = sum(method_stats.values())
            if total_recognitions > 0:
                yolo_pct = (method_stats['yolo_complete'] / total_recognitions) * 100
                hybrid_pct = (method_stats['hybrid_combined'] / total_recognitions) * 100
                single_pct = (method_stats['single_method'] / total_recognitions) * 100
                failed_pct = (method_stats['failed'] / total_recognitions) * 100
                
                print(f"   ğŸ§  è¯†åˆ«æ–¹æ³•: YOLOå®Œæ•´{method_stats['yolo_complete']}({yolo_pct:.0f}%) "
                      f"æ··åˆ{method_stats['hybrid_combined']}({hybrid_pct:.0f}%) "
                      f"å•ä¸€{method_stats['single_method']}({single_pct:.0f}%) "
                      f"å¤±è´¥{method_stats['failed']}({failed_pct:.0f}%)")
            
            # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
            perf_stats = self.stats['performance_stats']
            if perf_stats['average_recognition_time'] > 0:
                print(f"   âš¡ æ€§èƒ½: å¹³å‡{perf_stats['average_recognition_time']:.2f}s "
                      f"æœ€å¿«{perf_stats['fastest_recognition']:.2f}s "
                      f"æœ€æ…¢{perf_stats['slowest_recognition']:.2f}s")
            
            # æ˜¾ç¤ºå„æ‘„åƒå¤´çŠ¶æ€
            for camera_id, stats in self.stats['camera_stats'].items():
                camera_name = next((c['name'] for c in self.enabled_cameras if c['id'] == camera_id), camera_id)
                
                success_rate = (stats['successful_recognitions'] / stats['total_attempts'] * 100) if stats['total_attempts'] > 0 else 0
                last_time = stats.get('last_recognition_time', 'æœªçŸ¥')
                avg_duration = stats.get('average_duration', 0)
                best_quality = stats.get('best_quality_score', 0)
                
                # æ–¹æ³•ç»Ÿè®¡
                method_counts = stats['recognition_method_counts']
                method_str = f"Y{method_counts['yolo_complete']}H{method_counts['hybrid_combined']}S{method_counts['single_method']}"
                
                status_icon = "âœ…" if stats['successful_recognitions'] > 0 else "âšª"
                
                print(f"   {status_icon} {camera_name}: æˆåŠŸ{stats['successful_recognitions']}/{stats['total_attempts']} "
                      f"({success_rate:.0f}%) å¹³å‡{avg_duration:.2f}s è´¨é‡{best_quality:.2f} "
                      f"æ–¹æ³•[{method_str}] æœ€å:{last_time}")
    
    def _display_waiting(self, wait_time: float):
        """æ˜¾ç¤ºç­‰å¾…ä¿¡æ¯"""
        with self.display_lock:
            print(f"â³ ç­‰å¾… {wait_time:.1f}ç§’ åå¼€å§‹ä¸‹è½®å¾ªç¯...")
    
    def display_final_statistics(self):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡"""
        try:
            print("\nğŸ“ˆ æœ€ç»ˆè¿è¡Œç»Ÿè®¡")
            print("=" * 50)
            
            # è®¡ç®—è¿è¡Œæ—¶é—´
            total_time = datetime.now() - self.stats['start_time']
            print(f"â° æ€»è¿è¡Œæ—¶é—´: {str(total_time).split('.')[0]}")
            print(f"ğŸ”„ æ€»å¾ªç¯æ•°: {self.stats['total_cycles']}")
            
            # æ˜¾ç¤ºè¯†åˆ«æ–¹æ³•ç»Ÿè®¡
            method_stats = self.stats['recognition_method_stats']
            total_recognitions = sum(method_stats.values())
            if total_recognitions > 0:
                print(f"\nğŸ§  è¯†åˆ«æ–¹æ³•ç»Ÿè®¡ (æ€»è®¡: {total_recognitions} æ¬¡):")
                method_names = {
                    'yolo_complete': 'YOLOå®Œæ•´è¯†åˆ«',
                    'hybrid_combined': 'æ··åˆç»„åˆè¯†åˆ«',
                    'single_method': 'å•ä¸€æ–¹æ³•è¯†åˆ«',
                    'failed': 'è¯†åˆ«å¤±è´¥'
                }
                for method, count in method_stats.items():
                    if count > 0:
                        percentage = (count / total_recognitions) * 100
                        method_name = method_names.get(method, method)
                        print(f"  {method_name}: {count} æ¬¡ ({percentage:.1f}%)")
            
            # æ˜¾ç¤ºè´¨é‡ç»Ÿè®¡
            quality_stats = self.stats['quality_stats']
            total_quality = sum(quality_stats.values())
            if total_quality > 0:
                print(f"\nğŸ† è´¨é‡ç­‰çº§ç»Ÿè®¡ (æ€»è®¡: {total_quality} æ¬¡):")
                quality_names = {
                    'excellent': 'ä¼˜ç§€',
                    'good': 'è‰¯å¥½',
                    'average': 'ä¸€èˆ¬',
                    'poor': 'è¾ƒå·®',
                    'very_poor': 'å¾ˆå·®'
                }
                for level, count in quality_stats.items():
                    if count > 0:
                        percentage = (count / total_quality) * 100
                        level_name = quality_names.get(level, level)
                        print(f"  {level_name}: {count} æ¬¡ ({percentage:.1f}%)")
            
            # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
            perf_stats = self.stats['performance_stats']
            if perf_stats['total_recognition_time'] > 0:
                print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
                print(f"  æ€»è¯†åˆ«æ—¶é—´: {perf_stats['total_recognition_time']:.2f}ç§’")
                print(f"  å¹³å‡è¯†åˆ«æ—¶é—´: {perf_stats['average_recognition_time']:.2f}ç§’")
                print(f"  æœ€å¿«è¯†åˆ«: {perf_stats['fastest_recognition']:.2f}ç§’")
                print(f"  æœ€æ…¢è¯†åˆ«: {perf_stats['slowest_recognition']:.2f}ç§’")
            
            # æ˜¾ç¤ºå„æ‘„åƒå¤´è¯¦ç»†ç»Ÿè®¡
            print(f"\nğŸ“· å„æ‘„åƒå¤´è¯¦ç»†ç»Ÿè®¡:")
            for camera_id, stats in self.stats['camera_stats'].items():
                camera_name = next((c['name'] for c in self.enabled_cameras if c['id'] == camera_id), camera_id)
                
                success_rate = (stats['successful_recognitions'] / stats['total_attempts'] * 100) if stats['total_attempts'] > 0 else 0
                
                print(f"   {camera_name} (ID: {camera_id}):")
                print(f"     æ€»å°è¯•: {stats['total_attempts']} æ¬¡")
                print(f"     æˆåŠŸè¯†åˆ«: {stats['successful_recognitions']} æ¬¡ ({success_rate:.1f}%)")
                print(f"     å¤±è´¥è¯†åˆ«: {stats['failed_recognitions']} æ¬¡")
                print(f"     å¹³å‡è€—æ—¶: {stats['average_duration']:.2f}ç§’")
                print(f"     æœ€ä½³è´¨é‡: {stats['best_quality_score']:.3f}")
                
                # æ–¹æ³•åˆ†å¸ƒ
                method_counts = stats['recognition_method_counts']
                method_items = [f"{k}:{v}" for k, v in method_counts.items() if v > 0]
                if method_items:
                    print(f"     æ–¹æ³•åˆ†å¸ƒ: {', '.join(method_items)}")
                
                # è´¨é‡å†å²
                if stats['quality_history']:
                    avg_quality = sum(stats['quality_history']) / len(stats['quality_history'])
                    print(f"     å¹³å‡è´¨é‡: {avg_quality:.3f} (æœ€è¿‘{len(stats['quality_history'])}æ¬¡)")
            
            print("=" * 50)
            
        except Exception as e:
            print(f"âŒ æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='ç»Ÿä¸€è¯†åˆ«å™¨ç‰ˆæµ‹è¯•ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python see.py                           # é»˜è®¤é…ç½®è¿è¡Œ
  python see.py --interval 5              # è®¾ç½®å¾ªç¯é—´éš”ä¸º5ç§’
  python see.py --no-save                 # ç¦ç”¨ç»“æœä¿å­˜
  python see.py --strategy voting         # ä½¿ç”¨æŠ•ç¥¨èåˆç­–ç•¥
  python see.py --no-merge                # ç¦ç”¨ç»“æœåˆå¹¶
  python see.py --simple                  # ä½¿ç”¨ç®€åŒ–è¾“å‡ºæ ¼å¼
  python see.py --no-yolo                 # ç¦ç”¨YOLOè¯†åˆ«
  python see.py --no-details              # ä¸æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        """
    )
    
    parser.add_argument('--interval', type=int, default=3,
                       help='è¯†åˆ«å¾ªç¯é—´éš”(ç§’) (é»˜è®¤: 3)')
    parser.add_argument('--camera-delay', type=float, default=1.0,
                       help='æ‘„åƒå¤´åˆ‡æ¢å»¶è¿Ÿ(ç§’) (é»˜è®¤: 1.0)')
    parser.add_argument('--max-retries', type=int, default=2,
                       help='æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 2)')
    parser.add_argument('--no-save', action='store_true',
                       help='ç¦ç”¨ç»“æœä¿å­˜')
    parser.add_argument('--no-merge', action='store_true',
                       help='ç¦ç”¨ç»“æœåˆå¹¶')
    parser.add_argument('--strategy', choices=['weighted', 'voting', 'priority'], 
                       default='weighted', help='èåˆç­–ç•¥ (é»˜è®¤: weighted)')
    parser.add_argument('--simple', action='store_true',
                       help='ä½¿ç”¨ç®€åŒ–è¾“å‡ºæ ¼å¼')
    parser.add_argument('--no-yolo', action='store_true',
                       help='ç¦ç”¨YOLOè¯†åˆ«')
    parser.add_argument('--no-ocr', action='store_true',
                       help='ç¦ç”¨OCRè¯†åˆ«')
    parser.add_argument('--no-opencv', action='store_true',
                       help='ç¦ç”¨OpenCVèŠ±è‰²è¯†åˆ«')
    parser.add_argument('--no-details', action='store_true',
                       help='ä¸æ˜¾ç¤ºè¯¦ç»†è¯†åˆ«ç»“æœ')
    parser.add_argument('--no-quality', action='store_true',
                       help='ä¸æ˜¾ç¤ºè´¨é‡ä¿¡æ¯')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    try:
        args = parse_arguments()
        
        # åˆ›å»ºç»Ÿä¸€ç‰ˆç³»ç»Ÿå®ä¾‹
        system = UnifiedSeeSystem()
        
        # æ›´æ–°ç³»ç»Ÿé…ç½®
        system.config.update({
            'recognition_interval': args.interval,
            'camera_switch_delay': args.camera_delay,
            'max_retry_times': args.max_retries,
            'save_results': not args.no_save,
            'show_detailed_results': not args.no_details,
            'show_quality_info': not args.no_quality,
        })
        
        # æ›´æ–°è¯†åˆ«é…ç½®
        system.recognition_config.update({
            'output_format': 'simple' if args.simple else 'standard',
            'fusion_strategy': args.strategy,
            'enable_result_merging': not args.no_merge,
            'yolo_enabled': not args.no_yolo,
            'ocr_enabled': not args.no_ocr,
            'opencv_suit_enabled': not args.no_opencv,
            'include_quality_metrics': not args.no_quality,
        })
        
        # æ­¥éª¤1: è¯»å–æ‘„åƒå¤´é…ç½®
        if not system.step1_load_camera_config():
            return 1
        
        # æ˜¾ç¤ºç³»ç»Ÿé…ç½®
        print(f"\nğŸš€ ç»Ÿä¸€è¯†åˆ«å™¨ç‰ˆç³»ç»Ÿé…ç½®:")
        print(f"   å¾ªç¯é—´éš”: {system.config['recognition_interval']} ç§’")
        print(f"   åˆ‡æ¢å»¶è¿Ÿ: {system.config['camera_switch_delay']} ç§’")
        print(f"   æœ€å¤§é‡è¯•: {system.config['max_retry_times']} æ¬¡")
        print(f"   ä¿å­˜ç»“æœ: {'å¯ç”¨' if system.config['save_results'] else 'ç¦ç”¨'}")
        print(f"   è¾“å‡ºæ ¼å¼: {system.recognition_config['output_format']}")
        print(f"   ç»“æœåˆå¹¶: {'å¯ç”¨' if system.recognition_config['enable_result_merging'] else 'ç¦ç”¨'}")
        print(f"   èåˆç­–ç•¥: {system.recognition_config['fusion_strategy']}")
        print(f"   YOLOè¯†åˆ«: {'å¯ç”¨' if system.recognition_config['yolo_enabled'] else 'ç¦ç”¨'}")
        print(f"   OCRè¯†åˆ«: {'å¯ç”¨' if system.recognition_config['ocr_enabled'] else 'ç¦ç”¨'}")
        print(f"   OpenCVè¯†åˆ«: {'å¯ç”¨' if system.recognition_config['opencv_suit_enabled'] else 'ç¦ç”¨'}")
        print(f"   æ˜¾ç¤ºè¯¦æƒ…: {'å¯ç”¨' if system.config['show_detailed_results'] else 'ç¦ç”¨'}")
        print(f"   è´¨é‡ä¿¡æ¯: {'å¯ç”¨' if system.config['show_quality_info'] else 'ç¦ç”¨'}")
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        def signal_handler(signum, frame):
            print(f"\nğŸ“¡ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡å…³é—­ç³»ç»Ÿ...")
            system.shutdown_requested = True
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        print("\nğŸ”„ æŒ‰ Ctrl+C åœæ­¢ç³»ç»Ÿ")
        
        # è¿è¡Œä¸»å¾ªç¯
        system.run_main_loop()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        if system.stats['total_cycles'] > 0:
            system.display_final_statistics()
        
        print("ğŸ‘‹ ç»Ÿä¸€è¯†åˆ«å™¨ç‰ˆæµ‹è¯•ç³»ç»Ÿå·²å…³é—­")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())