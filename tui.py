#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶è¯†åˆ«æ¨é€ç³»ç»Ÿ - tui.py (æ–°ç‰ˆæœ¬)
ä¸šåŠ¡é€»è¾‘:
1. è¯»å–æ‘„åƒå¤´é…ç½®
2. è½®è¯¢æ‹ç…§
3. è½®è¯¢è£å‰ª
4. è½®è¯¢è¯†åˆ« (ä½¿ç”¨YOLOè¯†åˆ«å™¨)
5. è½®è¯¢æ¨é€
"""

import sys
import time
import json
import signal
import argparse
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional

# è·¯å¾„è®¾ç½®
def setup_project_paths():
    """è®¾ç½®é¡¹ç›®è·¯å¾„"""
    current_file = Path(__file__).resolve()
    project_root = current_file.parent
    
    project_root_str = str(project_root)
    if project_root_str not in sys.path:
        sys.path.insert(0, project_root_str)
    
    return project_root

PROJECT_ROOT = setup_project_paths()

class TuiSystem:
    """å®æ—¶è¯†åˆ«æ¨é€ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.shutdown_requested = False
        
        # ç³»ç»Ÿé…ç½®
        self.config = {
            'recognition_interval': 3,  # æ¯è½®å¾ªç¯é—´éš”(ç§’)
            'camera_switch_delay': 1,   # æ‘„åƒå¤´åˆ‡æ¢å»¶è¿Ÿ(ç§’)
            'max_retry_times': 3,       # æœ€å¤§é‡è¯•æ¬¡æ•°
            'retry_delay': 2,           # é‡è¯•å»¶è¿Ÿ(ç§’)
            'enable_websocket': True,   # å¯ç”¨WebSocketæ¨é€
            'save_recognition_results': True,  # ä¿å­˜è¯†åˆ«ç»“æœ
        }
        
        # æ‘„åƒå¤´é…ç½®
        self.enabled_cameras = []
        self.current_camera_index = 0
        
        # WebSocketå®¢æˆ·ç«¯
        self.websocket_client = None
        self.websocket_connected = False
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'start_time': datetime.now(),
            'total_cycles': 0,
            'camera_stats': {},  # æ¯ä¸ªæ‘„åƒå¤´çš„ç»Ÿè®¡
            'last_results': {},  # æœ€åä¸€æ¬¡è¯†åˆ«ç»“æœ
        }
        
        # æ˜¾ç¤ºçŠ¶æ€
        self.display_lock = threading.Lock()
        
        print("ğŸš€ å®æ—¶è¯†åˆ«æ¨é€ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def step1_load_camera_config(self) -> bool:
        """æ­¥éª¤1: è¯»å–æ‘„åƒå¤´é…ç½®"""
        try:
            print("\nğŸ“· æ­¥éª¤1: è¯»å–æ‘„åƒå¤´é…ç½®")
            print("-" * 50)
            
            # ä½¿ç”¨é…ç½®ç®¡ç†å™¨
            from src.core.config_manager import get_all_cameras
            
            result = get_all_cameras()
            if result['status'] != 'success':
                print(f"âŒ è·å–æ‘„åƒå¤´é…ç½®å¤±è´¥: {result['message']}")
                return False
            
            cameras = result['data']['cameras']
            if not cameras:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ‘„åƒå¤´é…ç½®")
                return False
            
            # è¿‡æ»¤å¯ç”¨çš„æ‘„åƒå¤´
            self.enabled_cameras = [c for c in cameras if c.get('enabled', True)]
            if not self.enabled_cameras:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ‘„åƒå¤´")
                return False
            
            print(f"âœ… æ‰¾åˆ° {len(self.enabled_cameras)} ä¸ªå¯ç”¨çš„æ‘„åƒå¤´:")
            for i, camera in enumerate(self.enabled_cameras):
                camera_id = camera['id']
                
                # åˆå§‹åŒ–æ‘„åƒå¤´ç»Ÿè®¡
                self.stats['camera_stats'][camera_id] = {
                    'total_attempts': 0,
                    'successful_photos': 0,
                    'successful_recognitions': 0,
                    'successful_pushes': 0,
                    'last_photo_time': None,
                    'last_recognition_time': None,
                    'last_push_time': None,
                    'last_result': None,
                }
                
                print(f"   {i+1}. {camera['name']} (ID: {camera_id}) - IP: {camera['ip']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è¯»å–æ‘„åƒå¤´é…ç½®å¤±è´¥: {e}")
            return False
    
    def step2_take_photo(self, camera_id: str) -> Dict[str, Any]:
        """æ­¥éª¤2: æ‹ç…§"""
        try:
            # å¯¼å…¥æ‹ç…§æ§åˆ¶å™¨
            from src.processors.photo_controller import take_photo_by_id
            
            start_time = time.time()
            result = take_photo_by_id(camera_id)
            duration = time.time() - start_time
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats['camera_stats'][camera_id]['total_attempts'] += 1
            
            if result['status'] == 'success':
                self.stats['camera_stats'][camera_id]['successful_photos'] += 1
                self.stats['camera_stats'][camera_id]['last_photo_time'] = datetime.now().strftime('%H:%M:%S')
                
                return {
                    'success': True,
                    'file_path': result['data']['file_path'],
                    'filename': result['data']['filename'],
                    'file_size': result['data']['file_size'],
                    'duration': duration
                }
            else:
                return {
                    'success': False,
                    'error': result['message'],
                    'duration': duration
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'duration': 0
            }
    
    def step3_crop_images(self, image_path: str) -> Dict[str, Any]:
        """æ­¥éª¤3: è£å‰ªå›¾ç‰‡"""
        try:
            from src.processors.image_cutter import process_image
            
            start_time = time.time()
            success = process_image(image_path)
            duration = time.time() - start_time
            
            if success:
                # æŸ¥æ‰¾è£å‰ªåçš„å›¾ç‰‡
                image_file = Path(image_path)
                cut_dir = image_file.parent / "cut"
                
                if cut_dir.exists():
                    pattern = f"{image_file.stem}_*.png"
                    cropped_files = list(cut_dir.glob(pattern))
                    # è¿‡æ»¤æ‰å·¦ä¸Šè§’å›¾ç‰‡ï¼Œåªè¦ä¸»å›¾ç‰‡
                    main_files = [f for f in cropped_files if not f.name.endswith('_left.png')]
                    main_files.sort(key=lambda x: x.name)
                    
                    return {
                        'success': True,
                        'cropped_files': [str(f) for f in main_files],
                        'count': len(main_files),
                        'duration': duration
                    }
                else:
                    return {
                        'success': False,
                        'error': 'è£å‰ªç›®å½•ä¸å­˜åœ¨',
                        'duration': duration
                    }
            else:
                return {
                    'success': False,
                    'error': 'å›¾ç‰‡è£å‰ªå¤±è´¥',
                    'duration': duration
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'duration': 0
            }
    
    def step4_recognize_images(self, camera_id: str, cropped_files: List[str]) -> Dict[str, Any]:
        """æ­¥éª¤4: è¯†åˆ«æ‰‘å…‹ç‰Œ"""
        try:
            recognition_results = {}
            successful_count = 0
            total_count = len(cropped_files)
            
            start_time = time.time()
            
            for image_path in cropped_files:
                position = self._extract_position_from_filename(Path(image_path).name)
                result = self._recognize_single_image(image_path)
                
                if result['success']:
                    successful_count += 1
                
                recognition_results[position] = result
            
            duration = time.time() - start_time
            
            # æ›´æ–°ç»Ÿè®¡
            if successful_count > 0:
                self.stats['camera_stats'][camera_id]['successful_recognitions'] += 1
                self.stats['camera_stats'][camera_id]['last_recognition_time'] = datetime.now().strftime('%H:%M:%S')
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = self._format_recognition_results(camera_id, recognition_results)
            
            return {
                'success': successful_count > 0,
                'results': recognition_results,
                'formatted_results': formatted_results,
                'successful_count': successful_count,
                'total_count': total_count,
                'success_rate': (successful_count / total_count * 100) if total_count > 0 else 0,
                'duration': duration
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'duration': 0
            }
    
    def step5_push_results(self, camera_id: str, formatted_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ­¥éª¤5: æ¨é€è¯†åˆ«ç»“æœ"""
        try:
            if not self.config['enable_websocket']:
                return {'success': True, 'message': 'WebSocketæ¨é€å·²ç¦ç”¨', 'duration': 0}
            
            start_time = time.time()
            
            # å°è¯•æ¨é€åˆ°è¯†åˆ«ç»“æœç®¡ç†å™¨
            push_result = self._push_to_recognition_manager(formatted_results)
            
            duration = time.time() - start_time
            
            # æ›´æ–°ç»Ÿè®¡
            if push_result['success']:
                self.stats['camera_stats'][camera_id]['successful_pushes'] += 1
                self.stats['camera_stats'][camera_id]['last_push_time'] = datetime.now().strftime('%H:%M:%S')
            
            return {
                'success': push_result['success'],
                'message': push_result['message'],
                'duration': duration
            }
            
        except Exception as e:
            return {
                'success': False,
                'message': str(e),
                'duration': 0
            }
    
    def _recognize_single_image(self, image_path: str) -> Dict[str, Any]:
        """è¯†åˆ«å•å¼ å›¾ç‰‡ - ä½¿ç”¨YOLOè¯†åˆ«å™¨"""
        try:
            # ä½¿ç”¨YOLOè¯†åˆ«å™¨
            from src.processors.poker_recognizer import recognize_poker_card
            
            result = recognize_poker_card(image_path)
            
            if result['success']:
                return {
                    'success': True,
                    'suit': result.get('suit', ''),
                    'rank': result.get('rank', ''),
                    'display_name': result.get('display_name', ''),
                    'confidence': result.get('confidence', 0),
                    'method': 'yolo'
                }
            else:
                return {
                    'success': False,
                    'error': result.get('error', 'è¯†åˆ«å¤±è´¥'),
                    'method': 'yolo'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'method': 'exception'
            }
    
    def _extract_position_from_filename(self, filename: str) -> str:
        """ä»æ–‡ä»¶åæå–ä½ç½®ä¿¡æ¯"""
        try:
            # æ–‡ä»¶åæ ¼å¼: camera_001_zhuang_1.png
            parts = filename.split('_')
            if len(parts) >= 4:
                return f"{parts[2]}_{parts[3].split('.')[0]}"
            return "unknown"
        except:
            return "unknown"
    
    def _format_recognition_results(self, camera_id: str, recognition_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–è¯†åˆ«ç»“æœç”¨äºæ¨é€"""
        positions = {}
        
        # æ ‡å‡†ä½ç½®åˆ—è¡¨
        standard_positions = ['zhuang_1', 'zhuang_2', 'zhuang_3', 'xian_1', 'xian_2', 'xian_3']
        
        for position in standard_positions:
            if position in recognition_results and recognition_results[position]['success']:
                result = recognition_results[position]
                positions[position] = {
                    'suit': result.get('suit', ''),
                    'rank': result.get('rank', ''),
                    'confidence': result.get('confidence', 0.0)
                }
            else:
                positions[position] = {
                    'suit': '',
                    'rank': '',
                    'confidence': 0.0
                }
        
        return {
            'camera_id': camera_id,
            'positions': positions,
            'timestamp': datetime.now().isoformat()
        }
    
    def _push_to_recognition_manager(self, formatted_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨é€åˆ°è¯†åˆ«ç»“æœç®¡ç†å™¨"""
        try:
            # ä½¿ç”¨è¯†åˆ«ç»“æœç®¡ç†å™¨
            from src.core.recognition_manager import receive_recognition_data
            
            result = receive_recognition_data(formatted_results)
            
            if result['status'] == 'success':
                return {'success': True, 'message': 'æ¨é€æˆåŠŸ'}
            else:
                return {'success': False, 'message': result.get('message', 'æ¨é€å¤±è´¥')}
                
        except Exception as e:
            return {'success': False, 'message': str(e)}
    
    def run_main_loop(self):
        """è¿è¡Œä¸»å¾ªç¯"""
        try:
            print(f"\nğŸ”„ å¼€å§‹å®æ—¶è¯†åˆ«æ¨é€å¾ªç¯")
            print(f"   è¯†åˆ«é—´éš”: {self.config['recognition_interval']} ç§’")
            print(f"   æ‘„åƒå¤´åˆ‡æ¢å»¶è¿Ÿ: {self.config['camera_switch_delay']} ç§’")
            print(f"   å¯ç”¨æ‘„åƒå¤´: {len(self.enabled_cameras)} ä¸ª")
            print("=" * 60)
            
            while not self.shutdown_requested:
                cycle_start_time = time.time()
                self.stats['total_cycles'] += 1
                
                # æ˜¾ç¤ºå¾ªç¯ä¿¡æ¯
                self._display_cycle_header()
                
                # è½®è¯¢å¤„ç†æ¯ä¸ªæ‘„åƒå¤´
                for i, camera in enumerate(self.enabled_cameras):
                    if self.shutdown_requested:
                        break
                    
                    camera_id = camera['id']
                    camera_name = camera.get('name', f'æ‘„åƒå¤´{camera_id}')
                    
                    # æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ‘„åƒå¤´
                    self._display_camera_processing(i + 1, len(self.enabled_cameras), camera_name, camera_id)
                    
                    # æ‰§è¡Œå®Œæ•´æµç¨‹
                    success = self._process_single_camera_workflow(camera_id)
                    
                    # æ‘„åƒå¤´åˆ‡æ¢å»¶è¿Ÿ
                    if i < len(self.enabled_cameras) - 1 and not self.shutdown_requested:
                        time.sleep(self.config['camera_switch_delay'])
                
                # æ˜¾ç¤ºæœ¬è½®ç»Ÿè®¡
                cycle_duration = time.time() - cycle_start_time
                self._display_cycle_summary(cycle_duration)
                
                # å¾ªç¯é—´éš”
                remaining_time = max(0, self.config['recognition_interval'] - cycle_duration)
                if remaining_time > 0 and not self.shutdown_requested:
                    self._display_waiting(remaining_time)
                    time.sleep(remaining_time)
                    
        except KeyboardInterrupt:
            print("\nâ¹ï¸  æ¥æ”¶åˆ°åœæ­¢ä¿¡å·")
            self.shutdown_requested = True
        except Exception as e:
            print(f"\nâŒ ä¸»å¾ªç¯å¼‚å¸¸: {e}")
            self.shutdown_requested = True
    
    def _process_single_camera_workflow(self, camera_id: str) -> bool:
        """å¤„ç†å•ä¸ªæ‘„åƒå¤´çš„å®Œæ•´å·¥ä½œæµç¨‹"""
        workflow_start_time = time.time()
        
        try:
            # æ­¥éª¤2: æ‹ç…§
            photo_result = self.step2_take_photo(camera_id)
            
            if not photo_result['success']:
                self._display_step_result("æ‹ç…§", False, photo_result['error'], photo_result['duration'])
                return False
            
            self._display_step_result("æ‹ç…§", True, f"{photo_result['filename']} ({photo_result['file_size']/1024:.1f}KB)", photo_result['duration'])
            
            # æ­¥éª¤3: è£å‰ª
            crop_result = self.step3_crop_images(photo_result['file_path'])
            
            if not crop_result['success']:
                self._display_step_result("è£å‰ª", False, crop_result['error'], crop_result['duration'])
                return False
            
            self._display_step_result("è£å‰ª", True, f"{crop_result['count']} ä¸ªåŒºåŸŸ", crop_result['duration'])
            
            # æ­¥éª¤4: è¯†åˆ«
            recognition_result = self.step4_recognize_images(camera_id, crop_result['cropped_files'])
            
            if not recognition_result['success']:
                self._display_step_result("è¯†åˆ«", False, recognition_result.get('error', 'è¯†åˆ«å¤±è´¥'), recognition_result['duration'])
                return False
            
            # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
            self._display_recognition_results(camera_id, recognition_result)
            
            # ä¿å­˜æœ€æ–°ç»“æœ
            self.stats['last_results'][camera_id] = recognition_result['formatted_results']
            
            # æ­¥éª¤5: æ¨é€
            push_result = self.step5_push_results(camera_id, recognition_result['formatted_results'])
            self._display_step_result("æ¨é€", push_result['success'], push_result['message'], push_result['duration'])
            
            # æ˜¾ç¤ºæ€»è€—æ—¶
            total_duration = time.time() - workflow_start_time
            print(f"      ğŸ’« æ€»è€—æ—¶: {total_duration:.2f}ç§’")
            
            return True
            
        except Exception as e:
            print(f"      âŒ å·¥ä½œæµç¨‹å¼‚å¸¸: {e}")
            return False
    
    def _display_cycle_header(self):
        """æ˜¾ç¤ºå¾ªç¯å¤´éƒ¨ä¿¡æ¯"""
        with self.display_lock:
            current_time = datetime.now().strftime('%H:%M:%S')
            print(f"\nğŸ”„ ç¬¬ {self.stats['total_cycles']} è½®å¾ªç¯ ({current_time})")
            print("=" * 60)
    
    def _display_camera_processing(self, current: int, total: int, camera_name: str, camera_id: str):
        """æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ‘„åƒå¤´"""
        with self.display_lock:
            print(f"\nğŸ“· ({current}/{total}) {camera_name} (ID: {camera_id})")
            print("-" * 40)
    
    def _display_step_result(self, step_name: str, success: bool, message: str, duration: float):
        """æ˜¾ç¤ºæ­¥éª¤ç»“æœ"""
        with self.display_lock:
            status_icon = "âœ…" if success else "âŒ"
            print(f"      {status_icon} {step_name}: {message} ({duration:.2f}s)")
    
    def _display_recognition_results(self, camera_id: str, recognition_result: Dict[str, Any]):
        """æ˜¾ç¤ºè¯†åˆ«ç»“æœ"""
        with self.display_lock:
            success_count = recognition_result['successful_count']
            total_count = recognition_result['total_count']
            success_rate = recognition_result['success_rate']
            duration = recognition_result['duration']
            
            print(f"      âœ… è¯†åˆ«: {success_count}/{total_count} æˆåŠŸ ({success_rate:.1f}%) ({duration:.2f}s)")
            
            # æ˜¾ç¤ºå…·ä½“è¯†åˆ«ç»“æœ
            results = recognition_result['results']
            position_names = {
                'zhuang_1': 'åº„1', 'zhuang_2': 'åº„2', 'zhuang_3': 'åº„3',
                'xian_1': 'é—²1', 'xian_2': 'é—²2', 'xian_3': 'é—²3'
            }
            
            recognized_cards = []
            for position, result in results.items():
                if result['success']:
                    pos_name = position_names.get(position, position)
                    display_name = result.get('display_name', 'N/A')
                    confidence = result.get('confidence', 0)
                    recognized_cards.append(f"{pos_name}:{display_name}({confidence:.2f})")
            
            if recognized_cards:
                cards_str = " | ".join(recognized_cards)
                print(f"         ğŸ´ {cards_str}")
    
    def _display_cycle_summary(self, cycle_duration: float):
        """æ˜¾ç¤ºå¾ªç¯æ±‡æ€»"""
        with self.display_lock:
            print(f"\nğŸ“Š æœ¬è½®æ±‡æ€»: è€—æ—¶ {cycle_duration:.2f}ç§’")
            
            # æ˜¾ç¤ºå„æ‘„åƒå¤´çŠ¶æ€
            for camera_id, stats in self.stats['camera_stats'].items():
                camera_name = next((c['name'] for c in self.enabled_cameras if c['id'] == camera_id), camera_id)
                
                success_icon = "âœ…" if stats['successful_recognitions'] > 0 else "âšª"
                last_time = stats.get('last_recognition_time', 'æœªçŸ¥')
                
                print(f"   {success_icon} {camera_name}: æ‹ç…§{stats['successful_photos']}/{stats['total_attempts']} "
                      f"è¯†åˆ«{stats['successful_recognitions']} æ¨é€{stats['successful_pushes']} "
                      f"æœ€å:{last_time}")
    
    def _display_waiting(self, wait_time: float):
        """æ˜¾ç¤ºç­‰å¾…ä¿¡æ¯"""
        with self.display_lock:
            print(f"â³ ç­‰å¾… {wait_time:.1f}ç§’ åå¼€å§‹ä¸‹è½®å¾ªç¯...")
    
    def display_final_statistics(self):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡"""
        try:
            print("\nğŸ“ˆ æœ€ç»ˆè¿è¡Œç»Ÿè®¡")
            print("=" * 50)
            
            # è®¡ç®—è¿è¡Œæ—¶é—´
            total_time = datetime.now() - self.stats['start_time']
            print(f"â° æ€»è¿è¡Œæ—¶é—´: {str(total_time).split('.')[0]}")
            print(f"ğŸ”„ æ€»å¾ªç¯æ•°: {self.stats['total_cycles']}")
            
            print(f"\nğŸ“· å„æ‘„åƒå¤´ç»Ÿè®¡:")
            for camera_id, stats in self.stats['camera_stats'].items():
                camera_name = next((c['name'] for c in self.enabled_cameras if c['id'] == camera_id), camera_id)
                
                photo_rate = (stats['successful_photos'] / stats['total_attempts'] * 100) if stats['total_attempts'] > 0 else 0
                
                print(f"   {camera_name} (ID: {camera_id}):")
                print(f"     æ‹ç…§: {stats['successful_photos']}/{stats['total_attempts']} ({photo_rate:.1f}%)")
                print(f"     è¯†åˆ«: {stats['successful_recognitions']} æ¬¡æˆåŠŸ")
                print(f"     æ¨é€: {stats['successful_pushes']} æ¬¡æˆåŠŸ")
            
            print("=" * 50)
            
        except Exception as e:
            print(f"âŒ æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='å®æ—¶è¯†åˆ«æ¨é€ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python tui.py                    # é»˜è®¤é…ç½®è¿è¡Œ
  python tui.py --interval 5       # è®¾ç½®å¾ªç¯é—´éš”ä¸º5ç§’
  python tui.py --no-push          # ç¦ç”¨æ¨é€åŠŸèƒ½
        """
    )
    
    parser.add_argument('--interval', type=int, default=3,
                       help='è¯†åˆ«å¾ªç¯é—´éš”(ç§’) (é»˜è®¤: 3)')
    parser.add_argument('--camera-delay', type=float, default=1.0,
                       help='æ‘„åƒå¤´åˆ‡æ¢å»¶è¿Ÿ(ç§’) (é»˜è®¤: 1.0)')
    parser.add_argument('--max-retries', type=int, default=3,
                       help='æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)')
    parser.add_argument('--no-push', action='store_true',
                       help='ç¦ç”¨æ¨é€åŠŸèƒ½')
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    try:
        args = parse_arguments()
        
        # åˆ›å»ºç³»ç»Ÿå®ä¾‹
        system = TuiSystem()
        
        # æ›´æ–°é…ç½®
        system.config.update({
            'recognition_interval': args.interval,
            'camera_switch_delay': args.camera_delay,
            'max_retry_times': args.max_retries,
            'enable_websocket': not args.no_push,
        })
        
        # æ­¥éª¤1: è¯»å–æ‘„åƒå¤´é…ç½®
        if not system.step1_load_camera_config():
            return 1
        
        # æ˜¾ç¤ºç³»ç»Ÿé…ç½®
        print(f"\nğŸš€ ç³»ç»Ÿé…ç½®:")
        print(f"   å¾ªç¯é—´éš”: {system.config['recognition_interval']} ç§’")
        print(f"   åˆ‡æ¢å»¶è¿Ÿ: {system.config['camera_switch_delay']} ç§’")
        print(f"   æœ€å¤§é‡è¯•: {system.config['max_retry_times']} æ¬¡")
        print(f"   æ¨é€åŠŸèƒ½: {'å¯ç”¨' if system.config['enable_websocket'] else 'ç¦ç”¨'}")
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        def signal_handler(signum, frame):
            print(f"\nğŸ“¡ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡å…³é—­ç³»ç»Ÿ...")
            system.shutdown_requested = True
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        print("\nğŸ”„ æŒ‰ Ctrl+C åœæ­¢ç³»ç»Ÿ")
        
        # è¿è¡Œä¸»å¾ªç¯
        system.run_main_loop()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        if system.stats['total_cycles'] > 0:
            system.display_final_statistics()
        
        print("ğŸ‘‹ å®æ—¶è¯†åˆ«æ¨é€ç³»ç»Ÿå·²å…³é—­")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())