#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾åƒé¢„å¤„ç†å™¨ - å¯¹è¯†åˆ«å‰çš„å›¾åƒè¿›è¡Œé¢„å¤„ç†
åŠŸèƒ½:
1. å›¾åƒç¼©æ”¾å’Œè£å‰ª
2. å›¾åƒå¢å¼ºï¼ˆäº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ï¼‰
3. å™ªå£°å»é™¤å’Œæ»¤æ³¢
4. é€è§†çŸ«æ­£
5. è§’åº¦æ£€æµ‹å’Œæ—‹è½¬
"""

import sys
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, Union
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
def setup_project_paths():
    """è®¾ç½®é¡¹ç›®è·¯å¾„ï¼Œç¡®ä¿å¯ä»¥æ­£ç¡®å¯¼å…¥æ¨¡å—"""
    current_file = Path(__file__).resolve()
    
    # æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« main.py çš„ç›®å½•ï¼‰
    project_root = current_file
    while project_root.parent != project_root:
        if (project_root / "main.py").exists():
            break
        project_root = project_root.parent
    
    # å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
    project_root_str = str(project_root)
    if project_root_str not in sys.path:
        sys.path.insert(0, project_root_str)
    
    return project_root

PROJECT_ROOT = setup_project_paths()

from src.core.utils import log_info, log_success, log_error, log_warning

class ImagePreprocessor:
    """å›¾åƒé¢„å¤„ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–å›¾åƒé¢„å¤„ç†å™¨"""
        self.config = config or {}
        self.cv2 = None
        self.pil = None
        self.cv2_available = False
        self.pil_available = False
        
        self._initialize_libraries()
        
        log_info("å›¾åƒé¢„å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ", "PREPROCESSOR")
    
    def _initialize_libraries(self):
        """åˆå§‹åŒ–ä¾èµ–åº“"""
        try:
            # åˆå§‹åŒ–OpenCV
            try:
                import cv2
                self.cv2 = cv2
                self.cv2_available = True
                log_success("OpenCVåº“åŠ è½½æˆåŠŸ", "PREPROCESSOR")
            except ImportError:
                log_warning("OpenCVåº“ä¸å¯ç”¨", "PREPROCESSOR")
            
            # åˆå§‹åŒ–PIL
            try:
                from PIL import Image, ImageEnhance, ImageFilter
                self.pil = Image
                self.pil_enhance = ImageEnhance
                self.pil_filter = ImageFilter
                self.pil_available = True
                log_success("PILåº“åŠ è½½æˆåŠŸ", "PREPROCESSOR")
            except ImportError:
                log_warning("PILåº“ä¸å¯ç”¨", "PREPROCESSOR")
            
            if not self.cv2_available and not self.pil_available:
                log_error("æ²¡æœ‰å¯ç”¨çš„å›¾åƒå¤„ç†åº“", "PREPROCESSOR")
                
        except Exception as e:
            log_error(f"å›¾åƒå¤„ç†åº“åˆå§‹åŒ–å¤±è´¥: {e}", "PREPROCESSOR")
    
    def preprocess_image(self, image_path: str, output_path: str = None) -> Dict[str, Any]:
        """
        é¢„å¤„ç†å›¾åƒ
        
        Args:
            image_path: è¾“å…¥å›¾åƒè·¯å¾„
            output_path: è¾“å‡ºå›¾åƒè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            é¢„å¤„ç†ç»“æœ
        """
        try:
            if not Path(image_path).exists():
                return {
                    'success': False,
                    'error': f'å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}'
                }
            
            # è·å–é¢„å¤„ç†é…ç½®
            pipeline = self.config.get('pipeline', ['resize', 'enhance', 'noise_reduction'])
            
            result = {
                'success': True,
                'original_path': image_path,
                'processed_path': output_path,
                'pipeline_steps': [],
                'processing_info': {}
            }
            
            # è¯»å–å›¾åƒ
            if self.cv2_available:
                image = self.cv2.imread(image_path)
                if image is None:
                    return {
                        'success': False,
                        'error': 'æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶'
                    }
                current_image = image.copy()
                using_opencv = True
            elif self.pil_available:
                image = self.pil.open(image_path)
                current_image = image.copy()
                using_opencv = False
            else:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰å¯ç”¨çš„å›¾åƒå¤„ç†åº“'
                }
            
            # è®°å½•åŸå§‹å›¾åƒä¿¡æ¯
            if using_opencv:
                original_height, original_width = image.shape[:2]
            else:
                original_width, original_height = image.size
            
            result['processing_info']['original_size'] = (original_width, original_height)
            
            # æ‰§è¡Œé¢„å¤„ç†ç®¡é“
            for step in pipeline:
                try:
                    if step == 'resize' and self._is_step_enabled('resize'):
                        current_image, step_info = self._resize_image(current_image, using_opencv)
                        result['pipeline_steps'].append('resize')
                        result['processing_info']['resize'] = step_info
                    
                    elif step == 'enhance' and self._is_step_enabled('enhance'):
                        current_image, step_info = self._enhance_image(current_image, using_opencv)
                        result['pipeline_steps'].append('enhance')
                        result['processing_info']['enhance'] = step_info
                    
                    elif step == 'noise_reduction' and self._is_step_enabled('noise_reduction'):
                        current_image, step_info = self._reduce_noise(current_image, using_opencv)
                        result['pipeline_steps'].append('noise_reduction')
                        result['processing_info']['noise_reduction'] = step_info
                    
                    elif step == 'perspective_correction' and self._is_step_enabled('perspective_correction'):
                        current_image, step_info = self._correct_perspective(current_image, using_opencv)
                        result['pipeline_steps'].append('perspective_correction')
                        result['processing_info']['perspective_correction'] = step_info
                        
                except Exception as e:
                    log_warning(f"é¢„å¤„ç†æ­¥éª¤å¤±è´¥ {step}: {e}", "PREPROCESSOR")
                    result['processing_info'][f'{step}_error'] = str(e)
            
            # ä¿å­˜å¤„ç†åçš„å›¾åƒ
            if output_path:
                success = self._save_image(current_image, output_path, using_opencv)
                if success:
                    result['processed_path'] = output_path
                    log_success(f"é¢„å¤„ç†å›¾åƒå·²ä¿å­˜: {output_path}", "PREPROCESSOR")
                else:
                    result['processed_path'] = None
                    log_error(f"ä¿å­˜é¢„å¤„ç†å›¾åƒå¤±è´¥: {output_path}", "PREPROCESSOR")
            
            # è®°å½•æœ€ç»ˆå›¾åƒä¿¡æ¯
            if using_opencv:
                final_height, final_width = current_image.shape[:2]
            else:
                final_width, final_height = current_image.size
            
            result['processing_info']['final_size'] = (final_width, final_height)
            result['processing_info']['size_changed'] = (original_width, original_height) != (final_width, final_height)
            
            return result
            
        except Exception as e:
            log_error(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}", "PREPROCESSOR")
            return {
                'success': False,
                'error': f'å›¾åƒé¢„å¤„ç†å¼‚å¸¸: {str(e)}'
            }
    
    def _is_step_enabled(self, step_name: str) -> bool:
        """æ£€æŸ¥é¢„å¤„ç†æ­¥éª¤æ˜¯å¦å¯ç”¨"""
        step_config = self.config.get(step_name, {})
        return step_config.get('enabled', True)
    
    def _resize_image(self, image: Union[np.ndarray, Any], using_opencv: bool) -> Tuple[Union[np.ndarray, Any], Dict[str, Any]]:
        """è°ƒæ•´å›¾åƒå¤§å°"""
        try:
            config = self.config.get('resize', {})
            target_width = config.get('target_width', 640)
            target_height = config.get('target_height', 480)
            keep_aspect_ratio = config.get('keep_aspect_ratio', True)
            
            if using_opencv:
                original_height, original_width = image.shape[:2]
                
                if keep_aspect_ratio:
                    # ä¿æŒå®½é«˜æ¯”
                    scale = min(target_width / original_width, target_height / original_height)
                    new_width = int(original_width * scale)
                    new_height = int(original_height * scale)
                else:
                    new_width = target_width
                    new_height = target_height
                
                interpolation_name = config.get('interpolation', 'INTER_LINEAR')
                interpolation = getattr(self.cv2, interpolation_name, self.cv2.INTER_LINEAR)
                
                resized_image = self.cv2.resize(image, (new_width, new_height), interpolation=interpolation)
                
                return resized_image, {
                    'original_size': (original_width, original_height),
                    'new_size': (new_width, new_height),
                    'scale_factor': scale if keep_aspect_ratio else (new_width/original_width, new_height/original_height)
                }
                
            else:  # PIL
                original_width, original_height = image.size
                
                if keep_aspect_ratio:
                    scale = min(target_width / original_width, target_height / original_height)
                    new_width = int(original_width * scale)
                    new_height = int(original_height * scale)
                else:
                    new_width = target_width
                    new_height = target_height
                
                resized_image = image.resize((new_width, new_height), self.pil.LANCZOS)
                
                return resized_image, {
                    'original_size': (original_width, original_height),
                    'new_size': (new_width, new_height),
                    'scale_factor': scale if keep_aspect_ratio else (new_width/original_width, new_height/original_height)
                }
                
        except Exception as e:
            log_error(f"å›¾åƒç¼©æ”¾å¤±è´¥: {e}", "PREPROCESSOR")
            return image, {'error': str(e)}
    
    def _enhance_image(self, image: Union[np.ndarray, Any], using_opencv: bool) -> Tuple[Union[np.ndarray, Any], Dict[str, Any]]:
        """å›¾åƒå¢å¼º"""
        try:
            config = self.config.get('enhance', {})
            brightness_factor = config.get('brightness_factor', 1.1)
            contrast_factor = config.get('contrast_factor', 1.2)
            saturation_factor = config.get('saturation_factor', 1.0)
            sharpness_factor = config.get('sharpness_factor', 1.1)
            auto_adjust = config.get('auto_adjust', True)
            
            enhanced_image = image
            adjustments = {}
            
            if using_opencv:
                # ä½¿ç”¨OpenCVè¿›è¡Œå¢å¼º
                if brightness_factor != 1.0 or contrast_factor != 1.0:
                    # äº®åº¦å’Œå¯¹æ¯”åº¦è°ƒæ•´
                    enhanced_image = self.cv2.convertScaleAbs(enhanced_image, 
                                                             alpha=contrast_factor, 
                                                             beta=(brightness_factor - 1.0) * 30)
                    adjustments['brightness'] = brightness_factor
                    adjustments['contrast'] = contrast_factor
                
                # é¥±å’Œåº¦è°ƒæ•´ï¼ˆè½¬æ¢åˆ°HSVï¼‰
                if saturation_factor != 1.0:
                    hsv = self.cv2.cvtColor(enhanced_image, self.cv2.COLOR_BGR2HSV)
                    hsv[:, :, 1] = hsv[:, :, 1] * saturation_factor
                    enhanced_image = self.cv2.cvtColor(hsv, self.cv2.COLOR_HSV2BGR)
                    adjustments['saturation'] = saturation_factor
                
                # é”åŒ–
                if sharpness_factor > 1.0:
                    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
                    sharpened = self.cv2.filter2D(enhanced_image, -1, kernel)
                    enhanced_image = self.cv2.addWeighted(enhanced_image, 2-sharpness_factor, sharpened, sharpness_factor-1, 0)
                    adjustments['sharpness'] = sharpness_factor
                
            else:  # PIL
                # ä½¿ç”¨PILè¿›è¡Œå¢å¼º
                if brightness_factor != 1.0:
                    enhancer = self.pil_enhance.Brightness(enhanced_image)
                    enhanced_image = enhancer.enhance(brightness_factor)
                    adjustments['brightness'] = brightness_factor
                
                if contrast_factor != 1.0:
                    enhancer = self.pil_enhance.Contrast(enhanced_image)
                    enhanced_image = enhancer.enhance(contrast_factor)
                    adjustments['contrast'] = contrast_factor
                
                if saturation_factor != 1.0:
                    enhancer = self.pil_enhance.Color(enhanced_image)
                    enhanced_image = enhancer.enhance(saturation_factor)
                    adjustments['saturation'] = saturation_factor
                
                if sharpness_factor != 1.0:
                    enhancer = self.pil_enhance.Sharpness(enhanced_image)
                    enhanced_image = enhancer.enhance(sharpness_factor)
                    adjustments['sharpness'] = sharpness_factor
            
            return enhanced_image, adjustments
            
        except Exception as e:
            log_error(f"å›¾åƒå¢å¼ºå¤±è´¥: {e}", "PREPROCESSOR")
            return image, {'error': str(e)}
    
    def _reduce_noise(self, image: Union[np.ndarray, Any], using_opencv: bool) -> Tuple[Union[np.ndarray, Any], Dict[str, Any]]:
        """å™ªå£°å»é™¤"""
        try:
            config = self.config.get('noise_reduction', {})
            method = config.get('method', 'gaussian_blur')
            kernel_size = config.get('kernel_size', 3)
            sigma = config.get('sigma', 0.5)
            
            processed_image = image
            process_info = {'method': method}
            
            if using_opencv:
                if method == 'gaussian_blur':
                    processed_image = self.cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)
                    process_info['kernel_size'] = kernel_size
                    process_info['sigma'] = sigma
                
                elif method == 'median_blur':
                    processed_image = self.cv2.medianBlur(image, kernel_size)
                    process_info['kernel_size'] = kernel_size
                
                elif method == 'bilateral_filter':
                    processed_image = self.cv2.bilateralFilter(image, 9, 75, 75)
                    process_info['parameters'] = (9, 75, 75)
                
                elif method == 'non_local_means':
                    if len(image.shape) == 3:  # å½©è‰²å›¾åƒ
                        processed_image = self.cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)
                    else:  # ç°åº¦å›¾åƒ
                        processed_image = self.cv2.fastNlMeansDenoising(image, None, 10, 7, 21)
                    process_info['parameters'] = 'auto'
                
            else:  # PIL
                if method == 'gaussian_blur':
                    processed_image = image.filter(self.pil_filter.GaussianBlur(radius=sigma))
                    process_info['radius'] = sigma
                
                elif method == 'median_blur':
                    processed_image = image.filter(self.pil_filter.MedianFilter(size=kernel_size))
                    process_info['size'] = kernel_size
                
                elif method == 'smooth':
                    processed_image = image.filter(self.pil_filter.SMOOTH)
                    process_info['filter'] = 'SMOOTH'
            
            return processed_image, process_info
            
        except Exception as e:
            log_error(f"å™ªå£°å»é™¤å¤±è´¥: {e}", "PREPROCESSOR")
            return image, {'error': str(e)}
    
    def _correct_perspective(self, image: Union[np.ndarray, Any], using_opencv: bool) -> Tuple[Union[np.ndarray, Any], Dict[str, Any]]:
        """é€è§†çŸ«æ­£"""
        try:
            if not using_opencv or not self.cv2_available:
                return image, {'error': 'é€è§†çŸ«æ­£éœ€è¦OpenCVæ”¯æŒ'}
            
            config = self.config.get('perspective_correction', {})
            auto_detect = config.get('auto_detect', True)
            
            if auto_detect:
                # è‡ªåŠ¨æ£€æµ‹çŸ©å½¢è½®å»“
                gray = self.cv2.cvtColor(image, self.cv2.COLOR_BGR2GRAY)
                edges = self.cv2.Canny(gray, 50, 150, apertureSize=3)
                
                contours, _ = self.cv2.findContours(edges, self.cv2.RETR_EXTERNAL, self.cv2.CHAIN_APPROX_SIMPLE)
                
                # å¯»æ‰¾æœ€å¤§çš„å››è¾¹å½¢è½®å»“
                largest_contour = None
                max_area = 0
                
                for contour in contours:
                    area = self.cv2.contourArea(contour)
                    if area > max_area:
                        # è¿‘ä¼¼è½®å»“
                        epsilon = 0.02 * self.cv2.arcLength(contour, True)
                        approx = self.cv2.approxPolyDP(contour, epsilon, True)
                        
                        if len(approx) == 4 and area > 1000:  # å››è¾¹å½¢ä¸”é¢ç§¯è¶³å¤Ÿå¤§
                            largest_contour = approx
                            max_area = area
                
                if largest_contour is not None:
                    # æ‰§è¡Œé€è§†å˜æ¢
                    src_points = largest_contour.reshape(4, 2).astype(np.float32)
                    
                    # è®¡ç®—ç›®æ ‡çŸ©å½¢çš„å°ºå¯¸
                    width = max(
                        np.linalg.norm(src_points[0] - src_points[1]),
                        np.linalg.norm(src_points[2] - src_points[3])
                    )
                    height = max(
                        np.linalg.norm(src_points[0] - src_points[3]),
                        np.linalg.norm(src_points[1] - src_points[2])
                    )
                    
                    dst_points = np.array([
                        [0, 0],
                        [width, 0],
                        [width, height],
                        [0, height]
                    ], dtype=np.float32)
                    
                    # è®¡ç®—é€è§†å˜æ¢çŸ©é˜µ
                    matrix = self.cv2.getPerspectiveTransform(src_points, dst_points)
                    
                    # åº”ç”¨é€è§†å˜æ¢
                    corrected_image = self.cv2.warpPerspective(image, matrix, (int(width), int(height)))
                    
                    return corrected_image, {
                        'corrected': True,
                        'contour_area': max_area,
                        'output_size': (int(width), int(height))
                    }
                else:
                    return image, {
                        'corrected': False,
                        'reason': 'æœªæ£€æµ‹åˆ°åˆé€‚çš„å››è¾¹å½¢è½®å»“'
                    }
            else:
                return image, {
                    'corrected': False,
                    'reason': 'æ‰‹åŠ¨é€è§†çŸ«æ­£æœªå®ç°'
                }
            
        except Exception as e:
            log_error(f"é€è§†çŸ«æ­£å¤±è´¥: {e}", "PREPROCESSOR")
            return image, {'error': str(e)}
    
    def _save_image(self, image: Union[np.ndarray, Any], output_path: str, using_opencv: bool) -> bool:
        """ä¿å­˜å›¾åƒ"""
        try:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            if using_opencv:
                return self.cv2.imwrite(str(output_file), image)
            else:
                image.save(str(output_file))
                return True
                
        except Exception as e:
            log_error(f"ä¿å­˜å›¾åƒå¤±è´¥: {e}", "PREPROCESSOR")
            return False
    
    def get_preprocessor_info(self) -> Dict[str, Any]:
        """è·å–é¢„å¤„ç†å™¨ä¿¡æ¯"""
        return {
            'cv2_available': self.cv2_available,
            'pil_available': self.pil_available,
            'config': self.config,
            'available_steps': [
                'resize', 'enhance', 'noise_reduction', 'perspective_correction'
            ]
        }

if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•å›¾åƒé¢„å¤„ç†å™¨")
    
    # æµ‹è¯•é…ç½®
    test_config = {
        'pipeline': ['resize', 'enhance', 'noise_reduction'],
        'resize': {
            'enabled': True,
            'target_width': 640,
            'target_height': 480,
            'keep_aspect_ratio': True,
            'interpolation': 'INTER_LINEAR'
        },
        'enhance': {
            'enabled': True,
            'brightness_factor': 1.1,
            'contrast_factor': 1.2,
            'saturation_factor': 1.0,
            'sharpness_factor': 1.1,
            'auto_adjust': True
        },
        'noise_reduction': {
            'enabled': True,
            'method': 'gaussian_blur',
            'kernel_size': 3,
            'sigma': 0.5
        },
        'perspective_correction': {
            'enabled': False,
            'auto_detect': True,
            'corner_detection_method': 'harris'
        }
    }
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = ImagePreprocessor(test_config)
    
    # è·å–é¢„å¤„ç†å™¨ä¿¡æ¯
    info = preprocessor.get_preprocessor_info()
    print(f"é¢„å¤„ç†å™¨ä¿¡æ¯: {info}")
    
    print("âœ… å›¾åƒé¢„å¤„ç†å™¨æµ‹è¯•å®Œæˆ")