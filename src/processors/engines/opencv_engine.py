#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenCVè¯†åˆ«å¼•æ“ - åŸºäºä¼ ç»Ÿè®¡ç®—æœºè§†è§‰çš„æ‰‘å…‹ç‰Œè¯†åˆ«
åŠŸèƒ½:
1. æ¨¡æ¿åŒ¹é…è¯†åˆ«
2. è½®å»“æ£€æµ‹å’Œå½¢çŠ¶åˆ†æ
3. é¢œè‰²åˆ†æè¯†åˆ«èŠ±è‰²
4. ç‰¹å¾ç‚¹åŒ¹é…ï¼ˆå¯é€‰ï¼‰
"""

import sys
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
def setup_project_paths():
    """è®¾ç½®é¡¹ç›®è·¯å¾„ï¼Œç¡®ä¿å¯ä»¥æ­£ç¡®å¯¼å…¥æ¨¡å—"""
    current_file = Path(__file__).resolve()
    
    # æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆåŒ…å« main.py çš„ç›®å½•ï¼‰
    project_root = current_file
    while project_root.parent != project_root:
        if (project_root / "main.py").exists():
            break
        project_root = project_root.parent
    
    # å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
    project_root_str = str(project_root)
    if project_root_str not in sys.path:
        sys.path.insert(0, project_root_str)
    
    return project_root

PROJECT_ROOT = setup_project_paths()

from src.processors.engines.base_engine import BaseEngine
from src.core.utils import log_info, log_success, log_error, log_warning

class OpenCVEngine(BaseEngine):
    """OpenCVè¯†åˆ«å¼•æ“"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–OpenCVå¼•æ“"""
        self.cv2 = None
        self.cv2_available = False
        self.templates = {}
        self.templates_path = None
        
        super().__init__("OpenCV", config)
    
    def _initialize_engine(self):
        """åˆå§‹åŒ–OpenCVå¼•æ“"""
        try:
            # æ£€æŸ¥OpenCVæ˜¯å¦å¯ç”¨
            try:
                import cv2
                self.cv2 = cv2
                self.cv2_available = True
                log_success(f"OpenCVåº“åŠ è½½æˆåŠŸ (ç‰ˆæœ¬: {cv2.__version__})", "OPENCV_ENGINE")
            except ImportError as e:
                log_error(f"OpenCVåº“ä¸å¯ç”¨: {e}", "OPENCV_ENGINE")
                self.cv2_available = False
                self.enabled = False
                return
            
            # åˆå§‹åŒ–æ¨¡æ¿åŒ¹é…
            if self.config.get('template_matching', {}).get('enabled', True):
                self._initialize_templates()
            
        except Exception as e:
            log_error(f"OpenCVå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}", "OPENCV_ENGINE")
            self.enabled = False
    
    def _initialize_templates(self):
        """åˆå§‹åŒ–æ¨¡æ¿"""
        try:
            self.templates_path = self.config.get('template_matching', {}).get('templates_path', 'src/config/templates/')
            
            # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            if not Path(self.templates_path).is_absolute():
                self.templates_path = PROJECT_ROOT / self.templates_path
            
            templates_dir = Path(self.templates_path)
            
            if not templates_dir.exists():
                log_warning(f"æ¨¡æ¿ç›®å½•ä¸å­˜åœ¨: {self.templates_path}", "OPENCV_ENGINE")
                return
            
            # åŠ è½½æ¨¡æ¿æ–‡ä»¶
            template_files = list(templates_dir.glob("*.png")) + list(templates_dir.glob("*.jpg"))
            
            for template_file in template_files:
                try:
                    template_name = template_file.stem
                    template_img = self.cv2.imread(str(template_file), self.cv2.IMREAD_GRAYSCALE)
                    
                    if template_img is not None:
                        self.templates[template_name] = template_img
                        log_info(f"åŠ è½½æ¨¡æ¿: {template_name}", "OPENCV_ENGINE")
                    else:
                        log_warning(f"æ¨¡æ¿åŠ è½½å¤±è´¥: {template_file}", "OPENCV_ENGINE")
                        
                except Exception as e:
                    log_error(f"åŠ è½½æ¨¡æ¿æ–‡ä»¶å¤±è´¥ {template_file}: {e}", "OPENCV_ENGINE")
            
            log_success(f"æ¨¡æ¿åŠ è½½å®Œæˆï¼Œå…± {len(self.templates)} ä¸ªæ¨¡æ¿", "OPENCV_ENGINE")
            
        except Exception as e:
            log_error(f"æ¨¡æ¿åˆå§‹åŒ–å¤±è´¥: {e}", "OPENCV_ENGINE")
    
    def _recognize_image(self, image_path: str) -> Dict[str, Any]:
        """ä½¿ç”¨OpenCVè¯†åˆ«å›¾ç‰‡"""
        try:
            if not self.cv2_available:
                return {
                    'success': False,
                    'error': 'OpenCVä¸å¯ç”¨'
                }
            
            # è¯»å–å›¾ç‰‡
            image = self.cv2.imread(image_path)
            if image is None:
                return {
                    'success': False,
                    'error': 'æ— æ³•è¯»å–å›¾ç‰‡'
                }
            
            gray = self.cv2.cvtColor(image, self.cv2.COLOR_BGR2GRAY)
            
            # å°è¯•ä¸åŒçš„è¯†åˆ«æ–¹æ³•
            results = []
            
            # æ–¹æ³•1: æ¨¡æ¿åŒ¹é…
            if self.config.get('template_matching', {}).get('enabled', True):
                template_result = self._template_matching(gray)
                if template_result['success']:
                    results.append(template_result)
            
            # æ–¹æ³•2: è½®å»“æ£€æµ‹
            if self.config.get('contour_detection', {}).get('enabled', True):
                contour_result = self._contour_detection(image, gray)
                if contour_result['success']:
                    results.append(contour_result)
            
            # æ–¹æ³•3: é¢œè‰²åˆ†æ
            if self.config.get('color_analysis', {}).get('enabled', True):
                color_result = self._color_analysis(image)
                if color_result['success']:
                    results.append(color_result)
            
            # æ–¹æ³•4: ç‰¹å¾åŒ¹é…ï¼ˆå¯é€‰ï¼‰
            if self.config.get('feature_matching', {}).get('enabled', False):
                feature_result = self._feature_matching(gray)
                if feature_result['success']:
                    results.append(feature_result)
            
            # é€‰æ‹©æœ€ä½³ç»“æœ
            if results:
                best_result = max(results, key=lambda x: x.get('confidence', 0))
                return best_result
            else:
                return {
                    'success': False,
                    'error': 'æ‰€æœ‰OpenCVæ–¹æ³•éƒ½æœªè¯†åˆ«æˆåŠŸ'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'OpenCVè¯†åˆ«å¼‚å¸¸: {str(e)}'
            }
    
    def _template_matching(self, gray_image: np.ndarray) -> Dict[str, Any]:
        """æ¨¡æ¿åŒ¹é…è¯†åˆ«"""
        try:
            if not self.templates:
                return {
                    'success': False,
                    'error': 'æ²¡æœ‰å¯ç”¨çš„æ¨¡æ¿'
                }
            
            threshold = self.config.get('template_matching', {}).get('threshold', 0.8)
            method_name = self.config.get('template_matching', {}).get('method', 'TM_CCOEFF_NORMED')
            
            # è·å–åŒ¹é…æ–¹æ³•
            method = getattr(self.cv2, method_name, self.cv2.TM_CCOEFF_NORMED)
            
            best_match = None
            best_confidence = 0
            
            for template_name, template in self.templates.items():
                # æ‰§è¡Œæ¨¡æ¿åŒ¹é…
                result = self.cv2.matchTemplate(gray_image, template, method)
                min_val, max_val, min_loc, max_loc = self.cv2.minMaxLoc(result)
                
                # æ ¹æ®æ–¹æ³•é€‰æ‹©åˆé€‚çš„å€¼
                if method in [self.cv2.TM_SQDIFF, self.cv2.TM_SQDIFF_NORMED]:
                    confidence = 1 - min_val
                    match_loc = min_loc
                else:
                    confidence = max_val
                    match_loc = max_loc
                
                if confidence > threshold and confidence > best_confidence:
                    best_confidence = confidence
                    best_match = {
                        'template_name': template_name,
                        'confidence': confidence,
                        'location': match_loc
                    }
            
            if best_match:
                # è§£ææ¨¡æ¿åç§°è·å–æ‰‘å…‹ç‰Œä¿¡æ¯
                card_info = self._parse_template_name(best_match['template_name'])
                
                return {
                    'success': True,
                    'suit': card_info['suit'],
                    'rank': card_info['rank'],
                    'suit_name': card_info['suit_name'],
                    'suit_symbol': card_info['suit_symbol'],
                    'display_name': card_info['display_name'],
                    'confidence': best_confidence,
                    'method': 'template_matching',
                    'template_name': best_match['template_name'],
                    'location': best_match['location']
                }
            else:
                return {
                    'success': False,
                    'error': f'æ¨¡æ¿åŒ¹é…ç½®ä¿¡åº¦ä½äºé˜ˆå€¼ {threshold}'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'æ¨¡æ¿åŒ¹é…å¼‚å¸¸: {str(e)}'
            }
    
    def _contour_detection(self, image: np.ndarray, gray_image: np.ndarray) -> Dict[str, Any]:
        """è½®å»“æ£€æµ‹è¯†åˆ«"""
        try:
            config = self.config.get('contour_detection', {})
            min_area = config.get('min_area', 1000)
            max_area = config.get('max_area', 50000)
            aspect_ratio_range = config.get('aspect_ratio_range', [0.6, 0.8])
            
            # è¾¹ç¼˜æ£€æµ‹
            edges = self.cv2.Canny(gray_image, 50, 150)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = self.cv2.findContours(edges, self.cv2.RETR_EXTERNAL, self.cv2.CHAIN_APPROX_SIMPLE)
            
            valid_contours = []
            
            for contour in contours:
                area = self.cv2.contourArea(contour)
                
                if min_area <= area <= max_area:
                    # è®¡ç®—è¾¹ç•ŒçŸ©å½¢
                    x, y, w, h = self.cv2.boundingRect(contour)
                    aspect_ratio = float(w) / h
                    
                    if aspect_ratio_range[0] <= aspect_ratio <= aspect_ratio_range[1]:
                        valid_contours.append({
                            'contour': contour,
                            'area': area,
                            'bbox': (x, y, w, h),
                            'aspect_ratio': aspect_ratio
                        })
            
            if valid_contours:
                # é€‰æ‹©æœ€å¤§çš„è½®å»“
                best_contour = max(valid_contours, key=lambda x: x['area'])
                
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šçš„å½¢çŠ¶åˆ†æé€»è¾‘
                # ç›®å‰è¿”å›ä¸€ä¸ªåŸºæœ¬çš„ç»“æœ
                confidence = min(0.8, best_contour['area'] / max_area)
                
                return {
                    'success': True,
                    'suit': 'unknown',
                    'rank': 'unknown',
                    'suit_name': 'æœªçŸ¥',
                    'suit_symbol': '?',
                    'display_name': 'æ£€æµ‹åˆ°æ‰‘å…‹ç‰Œ',
                    'confidence': confidence,
                    'method': 'contour_detection',
                    'contour_info': best_contour
                }
            else:
                return {
                    'success': False,
                    'error': 'æœªæ£€æµ‹åˆ°æœ‰æ•ˆè½®å»“'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'è½®å»“æ£€æµ‹å¼‚å¸¸: {str(e)}'
            }
    
    def _color_analysis(self, image: np.ndarray) -> Dict[str, Any]:
        """é¢œè‰²åˆ†æè¯†åˆ«èŠ±è‰²"""
        try:
            config = self.config.get('color_analysis', {})
            
            # è½¬æ¢åˆ°HSVé¢œè‰²ç©ºé—´
            hsv = self.cv2.cvtColor(image, self.cv2.COLOR_BGR2HSV)
            
            # çº¢è‰²èŒƒå›´ï¼ˆçº¢æ¡ƒå’Œæ–¹å—ï¼‰
            red_lower = np.array(config.get('red_threshold', [0, 50, 50])[:3])
            red_upper = np.array(config.get('red_threshold', [10, 255, 255])[3:6])
            red_mask1 = self.cv2.inRange(hsv, red_lower, red_upper)
            
            red_lower2 = np.array([170, 50, 50])
            red_upper2 = np.array([180, 255, 255])
            red_mask2 = self.cv2.inRange(hsv, red_lower2, red_upper2)
            
            red_mask = red_mask1 + red_mask2
            
            # é»‘è‰²èŒƒå›´ï¼ˆé»‘æ¡ƒå’Œæ¢…èŠ±ï¼‰
            black_lower = np.array(config.get('black_threshold', [0, 0, 0])[:3])
            black_upper = np.array(config.get('black_threshold', [180, 255, 30])[3:6])
            black_mask = self.cv2.inRange(hsv, black_lower, black_upper)
            
            # è®¡ç®—çº¢è‰²å’Œé»‘è‰²åƒç´ æ•°é‡
            red_pixels = np.sum(red_mask > 0)
            black_pixels = np.sum(black_mask > 0)
            
            total_pixels = image.shape[0] * image.shape[1]
            red_ratio = red_pixels / total_pixels
            black_ratio = black_pixels / total_pixels
            
            # åˆ¤æ–­é¢œè‰²
            if red_ratio > black_ratio and red_ratio > 0.01:
                # çº¢è‰²ç³»ï¼ˆçº¢æ¡ƒæˆ–æ–¹å—ï¼‰
                confidence = min(0.7, red_ratio * 10)
                
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´ç²¾ç»†çš„çº¢æ¡ƒ/æ–¹å—åŒºåˆ†é€»è¾‘
                # ç›®å‰ç®€å•è¿”å›çº¢æ¡ƒ
                return {
                    'success': True,
                    'suit': 'hearts',
                    'rank': 'unknown',
                    'suit_name': 'çº¢æ¡ƒ',
                    'suit_symbol': 'â™¥ï¸',
                    'display_name': 'â™¥ï¸?',
                    'confidence': confidence,
                    'method': 'color_analysis',
                    'color_info': {
                        'red_ratio': red_ratio,
                        'black_ratio': black_ratio
                    }
                }
            elif black_ratio > 0.02:
                # é»‘è‰²ç³»ï¼ˆé»‘æ¡ƒæˆ–æ¢…èŠ±ï¼‰
                confidence = min(0.7, black_ratio * 5)
                
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´ç²¾ç»†çš„é»‘æ¡ƒ/æ¢…èŠ±åŒºåˆ†é€»è¾‘
                # ç›®å‰ç®€å•è¿”å›é»‘æ¡ƒ
                return {
                    'success': True,
                    'suit': 'spades',
                    'rank': 'unknown',
                    'suit_name': 'é»‘æ¡ƒ',
                    'suit_symbol': 'â™ ï¸',
                    'display_name': 'â™ ï¸?',
                    'confidence': confidence,
                    'method': 'color_analysis',
                    'color_info': {
                        'red_ratio': red_ratio,
                        'black_ratio': black_ratio
                    }
                }
            else:
                return {
                    'success': False,
                    'error': 'æ— æ³•è¯†åˆ«æ‰‘å…‹ç‰Œé¢œè‰²'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f'é¢œè‰²åˆ†æå¼‚å¸¸: {str(e)}'
            }
    
    def _feature_matching(self, gray_image: np.ndarray) -> Dict[str, Any]:
        """ç‰¹å¾ç‚¹åŒ¹é…è¯†åˆ«"""
        try:
            config = self.config.get('feature_matching', {})
            detector_name = config.get('detector', 'ORB')
            matcher_name = config.get('matcher', 'BFMatcher')
            
            # åˆ›å»ºç‰¹å¾æ£€æµ‹å™¨
            if detector_name == 'ORB':
                detector = self.cv2.ORB_create()
            elif detector_name == 'SIFT':
                detector = self.cv2.SIFT_create()
            elif detector_name == 'SURF':
                detector = self.cv2.SURF_create()
            else:
                return {
                    'success': False,
                    'error': f'ä¸æ”¯æŒçš„ç‰¹å¾æ£€æµ‹å™¨: {detector_name}'
                }
            
            # æ£€æµ‹å…³é”®ç‚¹å’Œæè¿°ç¬¦
            keypoints, descriptors = detector.detectAndCompute(gray_image, None)
            
            if descriptors is None or len(descriptors) == 0:
                return {
                    'success': False,
                    'error': 'æœªæ£€æµ‹åˆ°ç‰¹å¾ç‚¹'
                }
            
            # è¿™é‡Œåº”è¯¥ä¸é¢„å…ˆå­˜å‚¨çš„æ¨¡æ¿ç‰¹å¾è¿›è¡ŒåŒ¹é…
            # ç›®å‰è¿”å›ä¸€ä¸ªåŸºæœ¬ç»“æœ
            confidence = min(0.6, len(keypoints) / 100)
            
            return {
                'success': True,
                'suit': 'unknown',
                'rank': 'unknown',
                'suit_name': 'æœªçŸ¥',
                'suit_symbol': '?',
                'display_name': 'ç‰¹å¾åŒ¹é…',
                'confidence': confidence,
                'method': 'feature_matching',
                'feature_info': {
                    'keypoints_count': len(keypoints),
                    'descriptor_shape': descriptors.shape if descriptors is not None else None
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ç‰¹å¾åŒ¹é…å¼‚å¸¸: {str(e)}'
            }
    
    def _parse_template_name(self, template_name: str) -> Dict[str, Any]:
        """è§£ææ¨¡æ¿åç§°è·å–æ‰‘å…‹ç‰Œä¿¡æ¯"""
        try:
            # å‡è®¾æ¨¡æ¿åç§°æ ¼å¼ä¸º: hearts_A, spades_K ç­‰
            parts = template_name.lower().split('_')
            
            if len(parts) >= 2:
                suit_part = parts[0]
                rank_part = parts[1]
                
                # èŠ±è‰²æ˜ å°„
                suit_mapping = {
                    'hearts': {'name': 'çº¢æ¡ƒ', 'symbol': 'â™¥ï¸', 'en': 'hearts'},
                    'spades': {'name': 'é»‘æ¡ƒ', 'symbol': 'â™ ï¸', 'en': 'spades'},
                    'diamonds': {'name': 'æ–¹å—', 'symbol': 'â™¦ï¸', 'en': 'diamonds'},
                    'clubs': {'name': 'æ¢…èŠ±', 'symbol': 'â™£ï¸', 'en': 'clubs'},
                    'h': {'name': 'çº¢æ¡ƒ', 'symbol': 'â™¥ï¸', 'en': 'hearts'},
                    's': {'name': 'é»‘æ¡ƒ', 'symbol': 'â™ ï¸', 'en': 'spades'},
                    'd': {'name': 'æ–¹å—', 'symbol': 'â™¦ï¸', 'en': 'diamonds'},
                    'c': {'name': 'æ¢…èŠ±', 'symbol': 'â™£ï¸', 'en': 'clubs'}
                }
                
                suit_info = suit_mapping.get(suit_part, {
                    'name': 'æœªçŸ¥', 'symbol': '?', 'en': 'unknown'
                })
                
                return {
                    'suit': suit_info['en'],
                    'rank': rank_part.upper(),
                    'suit_name': suit_info['name'],
                    'suit_symbol': suit_info['symbol'],
                    'display_name': f"{suit_info['symbol']}{rank_part.upper()}"
                }
            else:
                return {
                    'suit': 'unknown',
                    'rank': 'unknown',
                    'suit_name': 'æœªçŸ¥',
                    'suit_symbol': '?',
                    'display_name': template_name
                }
                
        except Exception:
            return {
                'suit': 'unknown',
                'rank': 'unknown',
                'suit_name': 'æœªçŸ¥',
                'suit_symbol': '?',
                'display_name': template_name
            }
    
    def is_available(self) -> bool:
        """æ£€æŸ¥OpenCVå¼•æ“æ˜¯å¦å¯ç”¨"""
        return self.enabled and self.cv2_available
    
    def get_opencv_info(self) -> Dict[str, Any]:
        """è·å–OpenCVå¼•æ“ä¿¡æ¯"""
        info = {
            'cv2_available': self.cv2_available,
            'cv2_version': self.cv2.__version__ if self.cv2 else None,
            'templates_count': len(self.templates),
            'templates_path': str(self.templates_path) if self.templates_path else None
        }
        
        # æ·»åŠ é…ç½®ä¿¡æ¯
        for method in ['template_matching', 'contour_detection', 'color_analysis', 'feature_matching']:
            method_config = self.config.get(method, {})
            info[method] = {
                'enabled': method_config.get('enabled', False),
                'config': method_config
            }
        
        return info

if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•OpenCVè¯†åˆ«å¼•æ“")
    
    # æµ‹è¯•é…ç½®
    test_config = {
        'enabled': True,
        'priority': 3,
        'template_matching': {
            'enabled': True,
            'templates_path': 'src/config/templates/',
            'threshold': 0.8,
            'method': 'TM_CCOEFF_NORMED'
        },
        'contour_detection': {
            'enabled': True,
            'min_area': 1000,
            'max_area': 50000,
            'aspect_ratio_range': [0.6, 0.8]
        },
        'color_analysis': {
            'enabled': True,
            'red_threshold': [0, 50, 50, 10, 255, 255],
            'black_threshold': [0, 0, 0, 180, 255, 30]
        },
        'feature_matching': {
            'enabled': False,
            'detector': 'ORB',
            'matcher': 'BFMatcher'
        }
    }
    
    # åˆ›å»ºOpenCVå¼•æ“
    opencv_engine = OpenCVEngine(test_config)
    
    print(f"å¼•æ“ä¿¡æ¯: {opencv_engine}")
    print(f"å¼•æ“å¯ç”¨: {opencv_engine.is_available()}")
    
    # è·å–OpenCVä¿¡æ¯
    opencv_info = opencv_engine.get_opencv_info()
    print(f"OpenCVä¿¡æ¯: {opencv_info}")
    
    # è·å–å¼•æ“ç»Ÿè®¡
    stats = opencv_engine.get_stats()
    print(f"å¼•æ“ç»Ÿè®¡: {stats}")
    
    print("âœ… OpenCVå¼•æ“æµ‹è¯•å®Œæˆ")